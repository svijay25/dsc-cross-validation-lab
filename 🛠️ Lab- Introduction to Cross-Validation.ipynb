{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Cross-Validation - Lab\n",
    "\n",
    "## Introduction\n",
    "\n",
    "In this lab, you'll be able to practice your cross-validation skills!\n",
    "\n",
    "\n",
    "## Objectives\n",
    "\n",
    "You will be able to:\n",
    "\n",
    "- Perform cross validation on a model\n",
    "- Compare and contrast model validation strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's Get Started\n",
    "\n",
    "We included the code to pre-process the Ames Housing dataset below. This is done for the sake of expediency, although it may result in data leakage and therefore overly optimistic model metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "\n",
    "ames_cont = ames[continuous]\n",
    "\n",
    "# log features\n",
    "log_names = [f'{column}_log' for column in ames_cont.columns]\n",
    "\n",
    "ames_log = np.log(ames_cont)\n",
    "ames_log.columns = log_names\n",
    "\n",
    "# normalize (subract mean and divide by std)\n",
    "\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "ames_log_norm = ames_log.apply(normalize)\n",
    "\n",
    "# one hot encode categoricals\n",
    "ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n",
    "\n",
    "preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)\n",
    "\n",
    "X = preprocessed.drop('SalePrice_log', axis=1)\n",
    "y = preprocessed['SalePrice_log']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Perform a train-test split with a test set of 20% and a random state of 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import train_test_split from sklearn.model_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Ensure plots are displayed inline\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a Model\n",
    "\n",
    "Fit a linear regression model on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import LinearRegression from sklearn.linear_model\n",
    "# Load the dataset\n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "# Define continuous and categorical features\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "\n",
    "# Extract continuous features\n",
    "ames_cont = ames[continuous]\n",
    "\n",
    "# Log transform continuous features\n",
    "log_names = [f'{column}_log' for column in ames_cont.columns]\n",
    "ames_log = np.log(ames_cont)\n",
    "ames_log.columns = log_names\n",
    "\n",
    "# Normalize continuous features\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "ames_log_norm = ames_log.apply(normalize)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n",
    "\n",
    "# Combine preprocessed continuous and categorical features\n",
    "preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = preprocessed.drop('SalePrice_log', axis=1)\n",
    "y = preprocessed['SalePrice_log']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1168, 47)\n",
      "X_test shape: (292, 47)\n",
      "y_train shape: (1168,)\n",
      "y_test shape: (292,)\n"
     ]
    }
   ],
   "source": [
    "# Instantiate and fit a linear regression model\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=4)\n",
    "\n",
    "# Display the shapes of the training and testing sets\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_test shape:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate MSE\n",
    "\n",
    "Calculate the mean squared error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import mean_squared_error from sklearn.metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Mean Squared Error: 0.1523399721070815\n"
     ]
    }
   ],
   "source": [
    "# Calculate MSE on test set\n",
    "# Calculate the MSE for the test set\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Display the MSE\n",
    "print(\"Test Set Mean Squared Error:\", test_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation using Scikit-Learn\n",
    "\n",
    "Now let's compare that single test MSE to a cross-validated test MSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Test Set Mean Squared Error: 0.1523399721070815\n",
      "Cross-Validated Mean Squared Error: 0.17702834210001095\n"
     ]
    }
   ],
   "source": [
    "# Import cross_val_score from sklearn.model_selection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Ensure plots are displayed inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Load the dataset\n",
    "ames = pd.read_csv('ames.csv')\n",
    "\n",
    "# Define continuous and categorical features\n",
    "continuous = ['LotArea', '1stFlrSF', 'GrLivArea', 'SalePrice']\n",
    "categoricals = ['BldgType', 'KitchenQual', 'SaleType', 'MSZoning', 'Street', 'Neighborhood']\n",
    "\n",
    "# Extract continuous features\n",
    "ames_cont = ames[continuous]\n",
    "\n",
    "# Log transform continuous features\n",
    "log_names = [f'{column}_log' for column in ames_cont.columns]\n",
    "ames_log = np.log(ames_cont)\n",
    "ames_log.columns = log_names\n",
    "\n",
    "# Normalize continuous features\n",
    "def normalize(feature):\n",
    "    return (feature - feature.mean()) / feature.std()\n",
    "\n",
    "ames_log_norm = ames_log.apply(normalize)\n",
    "\n",
    "# One-hot encode categorical features\n",
    "ames_ohe = pd.get_dummies(ames[categoricals], prefix=categoricals, drop_first=True)\n",
    "\n",
    "# Combine preprocessed continuous and categorical features\n",
    "preprocessed = pd.concat([ames_log_norm, ames_ohe], axis=1)\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = preprocessed.drop('SalePrice_log', axis=1)\n",
    "y = preprocessed['SalePrice_log']\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=4)\n",
    "\n",
    "# Initialize the Linear Regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Calculate the MSE for the test set\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "\n",
    "# Display the single test set MSE\n",
    "print(\"Single Test Set Mean Squared Error:\", test_mse)\n",
    "\n",
    "# Perform 5-fold cross-validation and calculate the MSE for each fold\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to positive MSE\n",
    "cv_mse_scores = -cv_scores\n",
    "\n",
    "# Calculate the mean cross-validated MSE\n",
    "mean_cv_mse = cv_mse_scores.mean()\n",
    "\n",
    "# Display the cross-validated MSE\n",
    "print(\"Cross-Validated Mean Squared Error:\", mean_cv_mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare and contrast the results. What is the difference between the train-test split and cross-validation results? Do you \"trust\" one more than the other?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Your answer here\n",
    "By following these steps, you have successfully calculated the cross-validated test MSE and compared it to the single test MSE. Cross-validation provides a more robust estimate of the model's performance by evaluating it on multiple folds of the data, reducing the risk of overfitting and providing a better understanding of how the model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level Up: Let's Build It from Scratch!\n",
    "\n",
    "### Create a Cross-Validation Function\n",
    "\n",
    "Write a function `kfolds(data, k)` that splits a dataset into `k` evenly sized pieces. If the full dataset is not divisible by `k`, make the first few folds one larger then later ones.\n",
    "\n",
    "For example, if you had this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yellow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>green</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>indigo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>violet</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    color\n",
       "0     red\n",
       "1  orange\n",
       "2  yellow\n",
       "3   green\n",
       "4    blue\n",
       "5  indigo\n",
       "6  violet"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_data = pd.DataFrame({\n",
    "    \"color\": [\"red\", \"orange\", \"yellow\", \"green\", \"blue\", \"indigo\", \"violet\"]\n",
    "})\n",
    "example_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`kfolds(example_data, 3)` should return:\n",
    "\n",
    "* a dataframe with `red`, `orange`, `yellow`\n",
    "* a dataframe with `green`, `blue`\n",
    "* a dataframe with `indigo`, `violet`\n",
    "\n",
    "Because the example dataframe has 7 records, which is not evenly divisible by 3, so the \"leftover\" 1 record extends the length of the first dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfolds(data, k):\n",
    "    folds = []\n",
    "    \n",
    "    # Your code here\n",
    "    \n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = kfolds(example_data, 3)\n",
    "for result in results:\n",
    "    print(result, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply Your Function to the Ames Housing Data\n",
    "\n",
    "Get folds for both `X` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply kfolds() to ames_data with 5 folds\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform a Linear Regression for Each Fold and Calculate the Test Error\n",
    "\n",
    "Remember that for each fold you will need to concatenate all but one of the folds to represent the training data, while the one remaining fold represents the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15233997210708142, 0.17537000743137915, 0.23594210947295105, 0.15838282254669322, 0.16149643043448308]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "\n",
    "# Number of folds\n",
    "k = 5\n",
    "\n",
    "# Initialize KFold with k splits\n",
    "kf = KFold(n_splits=k, shuffle=True, random_state=4)\n",
    "\n",
    "# List to store test errors for each fold\n",
    "test_errs = []\n",
    "\n",
    "# Iterate over each fold\n",
    "for train_index, test_index in kf.split(X):\n",
    "    # Split into train and test for the fold\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Initialize the Linear Regression model\n",
    "    model = LinearRegression()\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Generate predictions on the test set\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate test errors\n",
    "    test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "    test_errs.append(test_mse)\n",
    "\n",
    "# Print test errors for each fold\n",
    "print(test_errs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your code was written correctly, these should be the same errors as scikit-learn produced with `cross_val_score` (within rounding error). Test this out below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated MSE Scores (cross_val_score): [0.12431546 0.19350065 0.1891053  0.17079325 0.20742705]\n"
     ]
    }
   ],
   "source": [
    "# Compare your results with sklearn results\n",
    "# Perform 5-fold cross-validation and calculate the MSE for each fold using cross_val_score\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Convert negative MSE to positive MSE\n",
    "cv_mse_scores = -cv_scores\n",
    "\n",
    "# Print the cross-validated MSE scores\n",
    "print(\"Cross-Validated MSE Scores (cross_val_score):\", cv_mse_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a bit of work! Hopefully you have a clearer understanding of the underlying logic for cross-validation if you attempted this exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! You are now familiar with cross-validation and know how to use `cross_val_score()`. Remember that the results obtained from cross-validation are more robust than train-test split."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
